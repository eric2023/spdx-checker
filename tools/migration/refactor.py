#!/usr/bin/env python3
"""
SPDX Scanner è‡ªåŠ¨åŒ–é‡æ„å·¥å…·

æ­¤è„šæœ¬ç”¨äºè‡ªåŠ¨æ‰§è¡ŒSPDX Scanneré¡¹ç›®çš„ç›®å½•é‡æ„å·¥ä½œï¼Œ
åŒ…æ‹¬æ–‡ä»¶è¿ç§»ã€é‡å¤æ–‡ä»¶æ¸…ç†ã€ç›®å½•æ ‡å‡†åŒ–ç­‰ã€‚

ä½¿ç”¨æ–¹æ³•:
    python tools/migration/refactor.py [--dry-run] [--backup] [--verbose]

å‚æ•°:
    --dry-run: é¢„è§ˆæ¨¡å¼ï¼Œä¸å®é™…æ‰§è¡Œæ–‡ä»¶æ“ä½œ
    --backup: åœ¨æ“ä½œå‰åˆ›å»ºå¤‡ä»½
    --verbose: è¯¦ç»†è¾“å‡ºæ¨¡å¼
    --skip-tests: è·³è¿‡æµ‹è¯•æ–‡ä»¶è¿ç§»
    --skip-docs: è·³è¿‡æ–‡æ¡£æ–‡ä»¶è¿ç§»
"""

import os
import shutil
import argparse
import json
import logging
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass
from enum import Enum


class MigrationStatus(Enum):
    """è¿ç§»çŠ¶æ€æšä¸¾"""
    PENDING = "pending"
    IN_PROGRESS = "in_progress"
    COMPLETED = "completed"
    FAILED = "failed"
    SKIPPED = "skipped"


@dataclass
class FileMigration:
    """æ–‡ä»¶è¿ç§»é…ç½®"""
    source: str
    destination: str
    description: str
    required: bool = True
    backup_required: bool = False


@dataclass
class MigrationResult:
    """è¿ç§»ç»“æœ"""
    source: str
    destination: str
    status: MigrationStatus
    message: str
    backup_path: Optional[str] = None


class ProjectRefactor:
    """é¡¹ç›®é‡æ„å™¨"""

    def __init__(self, dry_run: bool = False, backup: bool = False, verbose: bool = False):
        self.dry_run = dry_run
        self.backup = backup
        self.verbose = verbose
        self.project_root = Path.cwd()
        self.migration_results: List[MigrationResult] = []
        self.backup_dir = self.project_root / "refactor_backup"

        # è®¾ç½®æ—¥å¿—
        self._setup_logging()

        # å®šä¹‰è¿ç§»è§„åˆ™
        self.migration_rules = self._define_migration_rules()

    def _setup_logging(self):
        """è®¾ç½®æ—¥å¿—é…ç½®"""
        log_level = logging.DEBUG if self.verbose else logging.INFO
        logging.basicConfig(
            level=log_level,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('refactor.log'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)

    def _define_migration_rules(self) -> List[FileMigration]:
        """å®šä¹‰è¿ç§»è§„åˆ™"""
        return [
            # æµ‹è¯•æ–‡ä»¶è¿ç§»
            FileMigration(
                source="integration_test.py",
                destination="tests/integration/test_integration_e2e.py",
                description="é›†æˆæµ‹è¯•æ–‡ä»¶è¿ç§»"
            ),
            FileMigration(
                source="simple_validation_test.py",
                destination="tests/integration/test_simple_validation.py",
                description="ç®€å•éªŒè¯æµ‹è¯•è¿ç§»"
            ),
            FileMigration(
                source="test_coverage.py",
                destination="tests/tools/test_coverage.py",
                description="è¦†ç›–ç‡æµ‹è¯•å·¥å…·è¿ç§»"
            ),
            FileMigration(
                source="test_examples.py",
                destination="tests/tools/test_examples.py",
                description="ç¤ºä¾‹æµ‹è¯•è¿ç§»"
            ),
            FileMigration(
                source="test_extensions_config.py",
                destination="tests/tools/test_extensions_config.py",
                description="æ‰©å±•é…ç½®æµ‹è¯•è¿ç§»"
            ),
            FileMigration(
                source="test_validation.py",
                destination="tests/test_validation_complete.py",
                description="éªŒè¯æµ‹è¯•è¿ç§»"
            ),
            FileMigration(
                source="validation_test.py",
                destination="tests/test_validation_helper.py",
                description="éªŒè¯è¾…åŠ©æµ‹è¯•è¿ç§»"
            ),
            FileMigration(
                source="validation_example.py",
                destination="tests/examples/test_validation_examples.py",
                description="éªŒè¯ç¤ºä¾‹è¿ç§»"
            ),
            FileMigration(
                source="validation_summary.py",
                destination="tests/tools/test_summary.py",
                description="æ‘˜è¦æµ‹è¯•è¿ç§»"
            ),

            # æ–‡æ¡£æ–‡ä»¶è¿ç§»
            FileMigration(
                source="BUILD_VALIDATION.md",
                destination="docs/development/build-validation.md",
                description="æ„å»ºéªŒè¯æ–‡æ¡£è¿ç§»"
            ),
            FileMigration(
                source="PRODUCTION_DEPLOYMENT.md",
                destination="docs/deployment/production-deployment.md",
                description="ç”Ÿäº§éƒ¨ç½²æ–‡æ¡£è¿ç§»"
            ),
            FileMigration(
                source="RELEASE_PREPARATION.md",
                destination="docs/development/release-preparation.md",
                description="å‘å¸ƒå‡†å¤‡æ–‡æ¡£è¿ç§»"
            ),
            FileMigration(
                source="EXAMPLES_VERIFICATION.md",
                destination="docs/testing/examples-verification.md",
                description="ç¤ºä¾‹éªŒè¯æ–‡æ¡£è¿ç§»"
            ),
            FileMigration(
                source="EXTENSIONS_CONFIG.md",
                destination="docs/testing/extensions-config.md",
                description="æ‰©å±•é…ç½®æ–‡æ¡£è¿ç§»"
            ),
            FileMigration(
                source="README_VALIDATION.md",
                destination="docs/testing/README-validation.md",
                description="READMEéªŒè¯æ–‡æ¡£è¿ç§»"
            ),
            FileMigration(
                source="VERIFICATION_REPORT.md",
                destination="docs/testing/verification-report.md",
                description="éªŒè¯æŠ¥å‘Šæ–‡æ¡£è¿ç§»"
            ),

            # ç‰¹æ®Šç›®å½•å¤„ç†
            FileMigration(
                source=".logs",
                destination="logs",
                description="æ—¥å¿—ç›®å½•æ ‡å‡†åŒ–",
                required=False
            ),
            FileMigration(
                source="task",
                destination="scripts/task_management",
                description="ä»»åŠ¡ç®¡ç†ç›®å½•è¿ç§»",
                required=False
            ),
        ]

    def run(self) -> bool:
        """æ‰§è¡Œé‡æ„"""
        self.logger.info("å¼€å§‹SPDX Scanneré¡¹ç›®é‡æ„...")

        # 1. é¢„å¤„ç†
        if not self._preprocess():
            return False

        # 2. æ‰§è¡Œè¿ç§»
        if not self._execute_migrations():
            return False

        # 3. åå¤„ç†
        if not self._postprocess():
            return False

        # 4. ç”ŸæˆæŠ¥å‘Š
        self._generate_report()

        return True

    def _preprocess(self) -> bool:
        """é¢„å¤„ç†é˜¶æ®µ"""
        self.logger.info("æ‰§è¡Œé¢„å¤„ç†...")

        try:
            # åˆ›å»ºç›®å½•ç»“æ„
            if not self._create_directory_structure():
                return False

            # åˆ›å»ºå¤‡ä»½
            if self.backup:
                if not self._create_backup():
                    return False

            # æ¸…ç†ç¼“å­˜æ–‡ä»¶
            if not self._clean_cache_files():
                return False

            return True

        except Exception as e:
            self.logger.error(f"é¢„å¤„ç†å¤±è´¥: {e}")
            return False

    def _create_directory_structure(self) -> bool:
        """åˆ›å»ºæ ‡å‡†ç›®å½•ç»“æ„"""
        directories = [
            "src/spdx_scanner/cli/commands",
            "src/spdx_scanner/cli/formatters",
            "src/spdx_scanner/core",
            "src/spdx_scanner/io",
            "src/spdx_scanner/config",
            "src/spdx_scanner/models",
            "src/spdx_scanner/utils",
            "tests/unit",
            "tests/integration",
            "tests/fixtures",
            "tests/utils",
            "tests/examples",
            "docs/usage",
            "docs/development",
            "docs/api",
            "docs/examples",
            "examples",
            "scripts",
            "tools/migration",
            "tools/analysis",
            "tools/maintenance",
            "logs",
            ".github/workflows"
        ]

        for directory in directories:
            dir_path = self.project_root / directory
            try:
                if not dir_path.exists():
                    if self.dry_run:
                        self.logger.info(f"[DRY RUN] åˆ›å»ºç›®å½•: {directory}")
                    else:
                        dir_path.mkdir(parents=True, exist_ok=True)
                        self.logger.info(f"åˆ›å»ºç›®å½•: {directory}")

            except Exception as e:
                self.logger.error(f"åˆ›å»ºç›®å½•å¤±è´¥ {directory}: {e}")
                return False

        return True

    def _create_backup(self) -> bool:
        """åˆ›å»ºå¤‡ä»½"""
        try:
            if self.dry_run:
                self.logger.info(f"[DRY RUN] åˆ›å»ºå¤‡ä»½åˆ°: {self.backup_dir}")
                return True

            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_path = self.project_root / f"refactor_backup_{timestamp}"

            self.logger.info(f"åˆ›å»ºå¤‡ä»½: {backup_path}")
            shutil.copytree(self.project_root, backup_path,
                          ignore=shutil.ignore_patterns(
                              '.git', '__pycache__', '*.pyc',
                              '.pytest_cache', 'refactor.log'
                          ))

            self.backup_dir = backup_path
            return True

        except Exception as e:
            self.logger.error(f"åˆ›å»ºå¤‡ä»½å¤±è´¥: {e}")
            return False

    def _clean_cache_files(self) -> bool:
        """æ¸…ç†ç¼“å­˜æ–‡ä»¶"""
        patterns_to_clean = [
            "__pycache__",
            "*.pyc",
            "*.pyo",
            ".pytest_cache",
            "*.egg-info"
        ]

        for pattern in patterns_to_clean:
            try:
                if self.dry_run:
                    self.logger.info(f"[DRY RUN] æ¸…ç†ç¼“å­˜æ–‡ä»¶: {pattern}")
                    continue

                # ä½¿ç”¨findå‘½ä»¤æ¸…ç†
                if pattern == "__pycache__":
                    result = os.system(f"find {self.project_root} -type d -name '__pycache__' -exec rm -rf {{}} + 2>/dev/null")
                elif pattern in ["*.pyc", "*.pyo"]:
                    result = os.system(f"find {self.project_root} -name '{pattern}' -delete 2>/dev/null")
                else:
                    result = os.system(f"find {self.project_root} -name '{pattern}' -type d -exec rm -rf {{}} + 2>/dev/null")

                if result == 0:
                    self.logger.info(f"æ¸…ç†å®Œæˆ: {pattern}")
                else:
                    self.logger.warning(f"éƒ¨åˆ†æ¸…ç†å¤±è´¥: {pattern}")

            except Exception as e:
                self.logger.warning(f"æ¸…ç† {pattern} æ—¶å‡ºé”™: {e}")

        return True

    def _execute_migrations(self) -> bool:
        """æ‰§è¡Œæ–‡ä»¶è¿ç§»"""
        self.logger.info("æ‰§è¡Œæ–‡ä»¶è¿ç§»...")

        success_count = 0
        for migration in self.migration_rules:
            if self._execute_single_migration(migration):
                success_count += 1
            else:
                if migration.required:
                    self.logger.error(f"å¿…éœ€è¿ç§»å¤±è´¥: {migration.source}")
                    return False

        self.logger.info(f"è¿ç§»å®Œæˆ: {success_count}/{len(self.migration_rules)}")
        return True

    def _execute_single_migration(self, migration: FileMigration) -> bool:
        """æ‰§è¡Œå•ä¸ªæ–‡ä»¶è¿ç§»"""
        source_path = self.project_root / migration.source
        dest_path = self.project_root / migration.destination

        try:
            # æ£€æŸ¥æºæ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not source_path.exists():
                message = f"æºæ–‡ä»¶ä¸å­˜åœ¨: {migration.source}"
                self._record_migration_result(migration, MigrationStatus.SKIPPED, message)
                self.logger.warning(message)
                return not migration.required

            # æ£€æŸ¥ç›®æ ‡ç›®å½•æ˜¯å¦å­˜åœ¨
            if not dest_path.parent.exists():
                if not self.dry_run:
                    dest_path.parent.mkdir(parents=True, exist_ok=True)

            # æ‰§è¡Œè¿ç§»
            if self.dry_run:
                message = f"[DRY RUN] è¿ç§» {migration.source} -> {migration.destination}"
                self.logger.info(message)
                self._record_migration_result(migration, MigrationStatus.COMPLETED, message)
                return True

            # åˆ›å»ºå¤‡ä»½ï¼ˆå¦‚æœéœ€è¦ï¼‰
            backup_path = None
            if migration.backup_required and self.backup:
                backup_path = self.backup_dir / migration.source
                shutil.copy2(source_path, backup_path)

            # ç§»åŠ¨æ–‡ä»¶
            if source_path.is_file():
                shutil.move(str(source_path), str(dest_path))
            else:
                shutil.move(str(source_path), str(dest_path))

            message = f"è¿ç§»å®Œæˆ: {migration.source} -> {migration.destination}"
            self.logger.info(message)
            self._record_migration_result(migration, MigrationStatus.COMPLETED, message, str(backup_path))
            return True

        except Exception as e:
            message = f"è¿ç§»å¤±è´¥ {migration.source}: {e}"
            self.logger.error(message)
            self._record_migration_result(migration, MigrationStatus.FAILED, message)
            return False

    def _record_migration_result(self, migration: FileMigration, status: MigrationStatus,
                               message: str, backup_path: Optional[str] = None):
        """è®°å½•è¿ç§»ç»“æœ"""
        result = MigrationResult(
            source=migration.source,
            destination=migration.destination,
            status=status,
            message=message,
            backup_path=backup_path
        )
        self.migration_results.append(result)

    def _postprocess(self) -> bool:
        """åå¤„ç†é˜¶æ®µ"""
        self.logger.info("æ‰§è¡Œåå¤„ç†...")

        try:
            # æ›´æ–°.gitignore
            if not self._update_gitignore():
                return False

            # ç”Ÿæˆè¿ç§»è„šæœ¬çš„æ”¹è¿›ç‰ˆæœ¬
            if not self._generate_improved_gitignore():
                return False

            return True

        except Exception as e:
            self.logger.error(f"åå¤„ç†å¤±è´¥: {e}")
            return False

    def _update_gitignore(self) -> bool:
        """æ›´æ–°.gitignoreæ–‡ä»¶"""
        gitignore_content = """# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# PyInstaller
*.manifest
*.spec

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
.hypothesis/
.pytest_cache/

# Jupyter Notebook
.ipynb_checkpoints

# Environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# IDE
.vscode/
.idea/
*.swp
*.swo
*~

# Logs
logs/
*.log

# OS
.DS_Store
Thumbs.db

# Editor specific
.cursor/
.cursorindexingignore

# Project specific
refactor_backup_*
refactor.log
"""

        try:
            gitignore_path = self.project_root / ".gitignore"
            if self.dry_run:
                self.logger.info(f"[DRY RUN] æ›´æ–° .gitignore")
                return True

            with open(gitignore_path, 'w', encoding='utf-8') as f:
                f.write(gitignore_content)

            self.logger.info("æ›´æ–° .gitignore å®Œæˆ")
            return True

        except Exception as e:
            self.logger.error(f"æ›´æ–° .gitignore å¤±è´¥: {e}")
            return False

    def _generate_improved_gitignore(self) -> bool:
        """ç”Ÿæˆæ”¹è¿›çš„.gitignoreæ–‡ä»¶"""
        improved_gitignore = """# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# PyInstaller
*.manifest
*.spec

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
.hypothesis/
.pytest_cache/

# Jupyter Notebook
.ipynb_checkpoints

# Environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# IDE
.vscode/
.idea/
*.swp
*.swo
*~

# Logs
logs/
*.log

# OS
.DS_Store
Thumbs.db

# Editor specific
.cursor/
.cursorindexingignore

# Project specific
refactor_backup_*
refactor.log

# Development tools
.mypy_cache/
.dmypy.json
dmypy.json

# Pyre type checker
.pyre/

# profiling data
.prof

# Sphinx documentation
docs/_build/

# Backup files
*.bak
*.backup
*~

# Temporary files
*.tmp
*.temp
"""

        try:
            improved_path = self.project_root / ".gitignore_improved"
            with open(improved_path, 'w', encoding='utf-8') as f:
                f.write(improved_gitignore)

            self.logger.info("ç”Ÿæˆæ”¹è¿›çš„ .gitignore æ–‡ä»¶: .gitignore_improved")
            return True

        except Exception as e:
            self.logger.error(f"ç”Ÿæˆæ”¹è¿›çš„ .gitignore å¤±è´¥: {e}")
            return False

    def _generate_report(self):
        """ç”Ÿæˆé‡æ„æŠ¥å‘Š"""
        self.logger.info("ç”Ÿæˆé‡æ„æŠ¥å‘Š...")

        # ç»Ÿè®¡ç»“æœ
        total = len(self.migration_results)
        completed = sum(1 for r in self.migration_results if r.status == MigrationStatus.COMPLETED)
        failed = sum(1 for r in self.migration_results if r.status == MigrationStatus.FAILED)
        skipped = sum(1 for r in self.migration_results if r.status == MigrationStatus.SKIPPED)

        # ç”ŸæˆæŠ¥å‘Š
        report = {
            "timestamp": datetime.now().isoformat(),
            "summary": {
                "total_migrations": total,
                "completed": completed,
                "failed": failed,
                "skipped": skipped,
                "success_rate": f"{(completed/total*100):.1f}%" if total > 0 else "0%"
            },
            "details": [
                {
                    "source": r.source,
                    "destination": r.destination,
                    "status": r.status.value,
                    "message": r.message,
                    "backup_path": r.backup_path
                }
                for r in self.migration_results
            ],
            "recommendations": self._generate_recommendations()
        }

        # ä¿å­˜æŠ¥å‘Š
        report_path = self.project_root / "refactor_report.json"
        try:
            with open(report_path, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False)

            self.logger.info(f"é‡æ„æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")

            # æ‰“å°æ‘˜è¦
            print("\\n" + "="*50)
            print("é‡æ„å®Œæˆæ‘˜è¦")
            print("="*50)
            print(f"æ€»è¿ç§»æ•°: {total}")
            print(f"æˆåŠŸ: {completed}")
            print(f"å¤±è´¥: {failed}")
            print(f"è·³è¿‡: {skipped}")
            print(f"æˆåŠŸç‡: {report['summary']['success_rate']}")
            print("="*50)

        except Exception as e:
            self.logger.error(f"ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}")

    def _generate_recommendations(self) -> List[str]:
        """ç”Ÿæˆåç»­å»ºè®®"""
        recommendations = [
            "è¿è¡Œæ‰€æœ‰æµ‹è¯•ä»¥ç¡®ä¿åŠŸèƒ½å®Œæ•´æ€§",
            "æ£€æŸ¥æ–°ç›®å½•ç»“æ„æ˜¯å¦ç¬¦åˆé¢„æœŸ",
            "æ›´æ–°CI/CDé…ç½®ä»¥é€‚åº”æ–°ç»“æ„",
            "æ›´æ–°å¼€å‘æ–‡æ¡£ä¸­çš„è·¯å¾„å¼•ç”¨",
            "è€ƒè™‘é‡æ„æºä»£ç æ¨¡å—ç»“æ„",
            "å»ºç«‹æŒç»­çš„æ–‡ä»¶ç»„ç»‡ç»´æŠ¤æœºåˆ¶"
        ]

        # æ ¹æ®è¿ç§»ç»“æœæ·»åŠ ç‰¹å®šå»ºè®®
        failed_migrations = [r for r in self.migration_results if r.status == MigrationStatus.FAILED]
        if failed_migrations:
            recommendations.append(f"æ‰‹åŠ¨å¤„ç† {len(failed_migrations)} ä¸ªå¤±è´¥çš„è¿ç§»")

        return recommendations


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="SPDX Scannerè‡ªåŠ¨åŒ–é‡æ„å·¥å…·")
    parser.add_argument("--dry-run", action="store_true",
                       help="é¢„è§ˆæ¨¡å¼ï¼Œä¸å®é™…æ‰§è¡Œæ–‡ä»¶æ“ä½œ")
    parser.add_argument("--backup", action="store_true",
                       help="åœ¨æ“ä½œå‰åˆ›å»ºå¤‡ä»½")
    parser.add_argument("--verbose", "-v", action="store_true",
                       help="è¯¦ç»†è¾“å‡ºæ¨¡å¼")
    parser.add_argument("--skip-tests", action="store_true",
                       help="è·³è¿‡æµ‹è¯•æ–‡ä»¶è¿ç§»")
    parser.add_argument("--skip-docs", action="store_true",
                       help="è·³è¿‡æ–‡æ¡£æ–‡ä»¶è¿ç§»")

    args = parser.parse_args()

    # åˆ›å»ºé‡æ„å™¨
    refactor = ProjectRefactor(
        dry_run=args.dry_run,
        backup=args.backup,
        verbose=args.verbose
    )

    print("SPDX Scanner è‡ªåŠ¨åŒ–é‡æ„å·¥å…·")
    print("="*40)

    if args.dry_run:
        print("âš ï¸  è¿è¡Œåœ¨é¢„è§ˆæ¨¡å¼ä¸‹ - ä¸ä¼šå®é™…ä¿®æ”¹æ–‡ä»¶")

    if args.backup:
        print("ğŸ’¾ å°†åˆ›å»ºå¤‡ä»½æ–‡ä»¶")

    print("\\nå¼€å§‹é‡æ„...")

    # æ‰§è¡Œé‡æ„
    success = refactor.run()

    if success:
        print("\\nâœ… é‡æ„å®Œæˆ!")
        if not args.dry_run:
            print("è¯·æ£€æŸ¥é‡æ„æŠ¥å‘Šå¹¶è¿è¡Œæµ‹è¯•ä»¥éªŒè¯ç»“æœã€‚")
    else:
        print("\\nâŒ é‡æ„å¤±è´¥! è¯·æ£€æŸ¥æ—¥å¿—æ–‡ä»¶è·å–è¯¦ç»†ä¿¡æ¯ã€‚")
        return 1

    return 0


if __name__ == "__main__":
    exit(main())